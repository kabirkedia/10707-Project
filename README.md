LLM for finetuning to generate Urdu poema. Files are here: [HERE](https://drive.google.com/drive/u/1/folders/1XaEskBdaG7tXs46Fi2fbiD6AyO60bFLP)
Model is here: [HERE](https://drive.google.com/drive/folders/1yq-G88Nf9joZcToyQNltQKDojNFsVmAd?usp=sharing)
Code is for Gemma and Llama. But Llama doesn't work with 8 vGPUs on ec2 so maybe we need much better GPUs
